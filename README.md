# ğŸ’¬ End-to-End Medical Chatbot

An intelligent, real-time AI chatbot built to deliver accurate, fast, and context-aware answers to your medical questions. Powered by Groq's lightning-fast LLMs, FAISS vector database, and Hugging Face embeddings, this chatbot is designed to make navigating through medical data easy, interactive, and insightful.

## ğŸš€ Live Features

- Powered by Groq LLMs: Choose from top-tier models like llama-3.3-70b-versatile, deepseek-r1-distill-llama-70b, and gemma2-9b-it for reliable and intelligent responses.

- Medical Expertise: The chatbot is trained and fine-tuned on health-focused dataset (PDF) to provide expert-level information.

- Real-Time Responses: Ask your medical questions and get immediate, contextual answers powered by Retrieval-Augmented Generation (RAG).

- Custom Model Selection: Flexibility to switch between Groq models as per your performance or accuracy needs.

- Chat History: Keeps track of your previous conversations for seamless user experience.

- Interactive Streamlit Interface: A clean, responsive UI for hassle-free interaction.

## ğŸ§  How It Works

- Data Extraction: PDF files are loaded using PyPDFLoader, then split into manageable text chunks using RecursiveCharacterTextSplitter.

- Embedding Generation: Chunks are embedded using Hugging Face's all-MiniLM-L6-v2 model.

- Vector Indexing: Chunks are stored in a FAISS vector index for fast similarity search.

- Query Retrieval: On user query, relevant document chunks are retrieved using a custom FAISS retriever.

- Answer Generation: Groq LLMs process the context and generate a concise, helpful response.

## ğŸ› ï¸ Tech Stack

- Python â€“ Backend logic and orchestration

- Streamlit â€“ Interactive user interface

- FAISS â€“ Fast vector search for document retrieval

- LangChain â€“ Chain of tools and logic for embeddings, LLMs, and prompts

- Groq LLMs â€“ High-performance large language models

- Hugging Face Embeddings â€“ Text-to-vector conversion

- dotenv â€“ Secure environment variable handling

ğŸ“ Directory Structure
```
.
â”œâ”€â”€ app.py                   # Main Streamlit app
â”œâ”€â”€ faiss_index.pkl          # Pickled FAISS index and text data
â”œâ”€â”€ .env                     # Groq API key
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py            # Embeddings and data loading logic
â”‚   â””â”€â”€ prompt.py            # Prompt template for QA chain
```

